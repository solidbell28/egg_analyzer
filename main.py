import streamlit as st
import yaml
import cv2
import numpy as np
from ultralytics import YOLO
from typing import Dict
from process import process_eggs
import torch


# fixing bug that appears while using streamlit with torch
torch.classes.__path__ = []


@st.cache_resource
def load_model(config: Dict) -> YOLO:
    return YOLO(config['model_path'])


@st.cache_resource
def load_config() -> Dict:
    with open('config.yaml', 'r') as f:
        return yaml.safe_load(f)


def main():
    st.title('–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —è–∏—Ü ü•ö')
    st.subheader('–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞')

    config = load_config()
    model = load_model(config)

    with st.sidebar:
        st.header('–ù–∞—Å—Ç—Ä–æ–π–∫–∏')
        with st.form('slider_form'):
            config['brightness_threshold'] = st.slider(
                '–ü–æ—Ä–æ–≥ —è—Ä–∫–æ—Å—Ç–∏',
                0, 255, config['brightness_threshold'],
                help='–ü–æ—Ä–æ–≥–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–∞ —Å–≤–µ—Ç–ª—ã–µ/—Ç–µ–º–Ω—ã–µ —è–π—Ü–∞'
            )
            config['conf_threshold'] = st.slider(
                '–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏',
                0.0, 1.0, config['conf_threshold'],
                help='–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏'
            )
            submit = st.form_submit_button("–ü—Ä–∏–º–µ–Ω–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ—Ä–æ–≥–æ–≤")

    uploaded_file = st.file_uploader(
        "–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
        type=['jpg', 'jpeg', 'png'],
        accept_multiple_files=False
    )

    if uploaded_file is not None:
        file_bytes = np.asarray(
            bytearray(uploaded_file.read()), dtype=np.uint8)
        image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)

        with st.spinner('–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...'):
            annotated_img, white, dark = process_eggs(config, model, image)

        original_image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        annotated_image_rgb = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)

        col1, col2 = st.columns(2)
        with col1:
            st.image(original_image_rgb,
                     caption='–ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ',
                     use_container_width=True)

        with col2:
            st.image(annotated_image_rgb,
                     caption='–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏',
                     use_container_width=True)

        st.success(f"**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞:**")
        col_stat1, col_stat2 = st.columns(2)
        with col_stat1:
            st.metric(label="–°–≤–µ—Ç–ª—ã–µ —è–π—Ü–∞", value=white)
        with col_stat2:
            st.metric(label="–¢–µ–º–Ω—ã–µ —è–π—Ü–∞", value=dark)


if __name__ == '__main__':
    main()
